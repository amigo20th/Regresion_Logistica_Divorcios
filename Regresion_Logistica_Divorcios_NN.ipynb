{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regresion_Logistica_Divorcios_NN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru6jbXEwF1Dh",
        "colab_type": "text"
      },
      "source": [
        "<h1>Regresión Logística</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gObF_TG5GARn",
        "colab_type": "text"
      },
      "source": [
        "En este Notebook vamos a hacer una regresión logístia por medio de una sola neurona, o perceptró. El proceso va a ser llevado desde un inicio con el mayor nivel de explicación que me sea posible dar.\n",
        "\n",
        "El ejercicio está basado en el Notebook de Andrew Ng llamado Logistic Regression with a Neural Network, aunque el ejercicio está excelentemente explicado quiero replicarlo, esto lo voy a hacer en mis propias palabras es por eso que lo estoy haciendo en español.\n",
        "\n",
        "LLamamos nuestras librerias a ocupar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afWmtlmIF-LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdnKpTw7IWzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/sample_data/divorce.csv\", sep = '\\t', header=None)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f0u_CqJ2tIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataframe de divorciados\n",
        "df_div = df[df[54] == 1]\n",
        "# dataframe de los casados\n",
        "df_cas = df[df[54] == 0]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p58dNMeb4L95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_div = df_div[54]\n",
        "target_cas = df_cas[54]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjxmVQqz4t_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_div = df_div.iloc[:, :-1]\n",
        "df_cas = df_cas.iloc[:, :-1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmiKV7-164g8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "90307e91-9b00-4235-990f-ec1d2c34c390"
      },
      "source": [
        "print(df_div.shape)\n",
        "print(df_cas.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(84, 54)\n",
            "(86, 54)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spzf0EL64uxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_div, X_test_div, y_train_div, y_test_div = train_test_split(df_div, target_div, train_size=0.8)\n",
        "X_train_cas, X_test_cas, y_train_cas, y_test_cas = train_test_split(df_cas, target_cas, train_size=0.8)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbQO5tG_42De",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1af9edd5-c6fe-4fcb-e2e9-bea2b1256f82"
      },
      "source": [
        "print(X_train_div.shape)\n",
        "print(X_test_div.shape)\n",
        "print(y_train_div.shape)\n",
        "print(y_test_div.shape)\n",
        "print()\n",
        "print(X_train_cas.shape)\n",
        "print(X_test_cas.shape)\n",
        "print(y_train_cas.shape)\n",
        "print(y_test_cas.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(67, 54)\n",
            "(17, 54)\n",
            "(67,)\n",
            "(17,)\n",
            "\n",
            "(68, 54)\n",
            "(18, 54)\n",
            "(68,)\n",
            "(18,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YZkdkSt5kb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pd.concat((X_train_div, X_train_cas), axis=0)\n",
        "X_test =  pd.concat((X_test_div , X_test_cas), axis=0)\n",
        "y_train = pd.concat((y_train_div, y_train_cas), axis=0)\n",
        "y_test =  pd.concat((y_test_div,  y_test_cas), axis=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkHixjkS6Znj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "c72134b5-07c0-4302-9d47-458f59afa133"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135, 54)\n",
            "(35, 54)\n",
            "(135,)\n",
            "(35,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSqx0p_-6si3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sacamos el numpy de cada dataframe y lo guardamos con su \n",
        "# traspusta para acomodarlo en el convenio\n",
        "X_train = X_train.values\n",
        "X_train = X_train.T\n",
        "\n",
        "X_test = X_test.values\n",
        "X_test = X_test.T"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8O7h_K2e0Dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizamos el conjunto X de entrenamiento y de test\n",
        "# como el valor máximo que podemos tener es 4 solo vamos a dividir entre en máximo\n",
        "X_train = X_train / 4\n",
        "X_test = X_test / 4\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23bQN-f6GWAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e42681a1-feca-4e68-9b56-85889f27cb03"
      },
      "source": [
        "# Como podemos ver el valor de m en nuestro ejemplo es 135\n",
        "# y el tamaño del conjunto de prueba es de 35\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54, 135)\n",
            "(54, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TXc-kAvZwC0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dd46866c-024f-4788-976d-e00df76520f4"
      },
      "source": [
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135,)\n",
            "(35,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39V6WZZqaMik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.reshape((1, y_train.shape[0]))\n",
        "y_test = y_test.reshape((1, y_test.shape[0]))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xEGnrylbHb6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0e5126c6-d0be-4f22-c0f8-eba73dc2976c"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 135)\n",
            "(1, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp-rLUQTJpiP",
        "colab_type": "text"
      },
      "source": [
        "Creamos las funciones necesarias para ejecutar la\n",
        "regresión logística.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoSTt1AYHjra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Función de activación\n",
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Computa el sigmoide de z\n",
        "\n",
        "    Argumentos:\n",
        "    z -- Un escalar o un array de numpy de cualquier tamaño.\n",
        "\n",
        "    Returna:\n",
        "    s -- sigmoid(z)\n",
        "    \"\"\"\n",
        "    s = 1 / (1 + np.exp(-z))\n",
        "    return s"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok66geGAJ_ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Función de inicialización de pesos en ceros\n",
        "def initialize_with_zeros(dim):\n",
        "    \"\"\"\n",
        "    Esta función crea un vector de ceros con dimensiones (dim, 1) para w e inicializa b a cero\n",
        "    \n",
        "    Argument:\n",
        "    dim -- tamaño de el vector w que queremos (o el número de parámetros en este caso)\n",
        "    size of the w vector we want (or number of parameters in this case)\n",
        "    \n",
        "    Returna:\n",
        "    w -- el vector inicializado de dimensiones (dim, 1)\n",
        "    b -- el escalar inicializado de dimensiones (dim, 1)\n",
        "    \"\"\"\n",
        "    w = np.zeros(shape=(dim, 1))\n",
        "    b = 0\n",
        "    assert(w.shape == (dim, 1))\n",
        "    assert(isinstance(b, float) or isinstance(b, int))\n",
        "    return w, b"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1827-iyLIAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Función de propagación\n",
        "def propagate(w, b, X, Y):\n",
        "    \"\"\"\n",
        "    Implementa la función costo y su gradiente para la propagación explicada anteriormente\n",
        "\n",
        "    Argumentos:\n",
        "    w -- weights o pesos, un array numpy de tamaño (num_atributos[54 en este caso], 1) \n",
        "    b -- bias o sesgo, un escalar\n",
        "    X -- datos con el tamaño (num_atributos[54 en este caso], numbero de ejemplos)\n",
        "    Y -- vector \"etiqueta\" verdad(contiene 0 si esta casado, 1 si está divorsiado) de tamaño (1, numero de ejemplos)\n",
        "\n",
        "    Returna:\n",
        "    cost -- la probabilidad del costo logarítmico negativo para la regresión logística\n",
        "    dw -- gradiente de la perdida con respecto a w, así tiene la misma dimensión de w \n",
        "    db -- gradiente de la perdida con respecto a b, así tiene la misma dimensión de b    \n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    \n",
        "    # PROPAGACIÓN HACIA DELANTE (DESDE X A COST)\n",
        "    A = sigmoid(np.dot(w.T, X) + b)                         # computa la activación\n",
        "    cost = np.sum( Y*np.log(A) + (1-Y)*np.log(1-A) ) / -m   # computa el cost\n",
        "    \n",
        "    # PROPAGACIÓN HACIA ATRÁS (PARA ENCONTRAR EL GRADIENTE)\n",
        "    dw = np.dot(X, (A-Y).T) / m\n",
        "    db = np.sum(A-Y) / m\n",
        "\n",
        "    assert(dw.shape == w.shape)\n",
        "    assert(db.dtype == float)\n",
        "    cost = np.squeeze(cost)\n",
        "    assert(cost.shape == ())\n",
        "    \n",
        "    grads = {\"dw\": dw,\n",
        "             \"db\": db}\n",
        "    \n",
        "    return grads, cost"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st43ZeovRb5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FUNCIÓN: optimizar\n",
        "\n",
        "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
        "    \"\"\"\n",
        "    Esta función optimiza w y b por correr un algoritmo de gradiente descendiente\n",
        "    \n",
        "    Argumentos:\n",
        "    w -- weights o pesos, un array numpy de tamaño (número de atributos, 1)\n",
        "    b -- bias o sesgo, un escalar\n",
        "    X -- datos con el tamaño (num_atributos[54 en este caso], numbero de ejemplos)\n",
        "    Y -- vector \"etiqueta\" verdad(contiene 0 si esta casado, 1 si está divorsiado) de tamaño (1, numero de ejemplos)\n",
        "    num_iterations -- número de iteraciones del ciclo de optimización\n",
        "    learning_rate -- tasa de aprendizaje de la regla de actualización del gradiente descendiente\n",
        "    print_cost -- Si es True imprime la pérdida cada 100 pasos \n",
        "    \n",
        "    Returna:\n",
        "    params -- diccionario que contiene los pesos w y el sesgo b\n",
        "    grads -- diccionario que contiene los gradiente de los pesos y el sesgo respecto a la función cost\n",
        "    costs -- lista de todos los costos computados durante la optimización, esto será usado para graficar la curva de aprendizaje     \n",
        "    \"\"\"\n",
        "    \n",
        "    costs = []\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "        \n",
        "        \n",
        "        grads, cost = propagate(w, b, X, Y)\n",
        "\n",
        "        #  Resupera las derivadas desde grads\n",
        "        dw = grads[\"dw\"]\n",
        "        db = grads[\"db\"]\n",
        "        \n",
        "        w = w - learning_rate*dw\n",
        "        b = b - learning_rate*db\n",
        "        \n",
        "        # Guanta los costos\n",
        "        if i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "        \n",
        "        # Imprime los costos cada 100 iteraciones de entrenamiento\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "    \n",
        "    params = {\"w\": w,\n",
        "              \"b\": b}\n",
        "    \n",
        "    grads = {\"dw\": dw,\n",
        "             \"db\": db}\n",
        "    \n",
        "    return params, grads, costs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_bC_WfuReG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FUNCIÓN: predecir\n",
        "\n",
        "def predict(w, b, X):\n",
        "    '''\n",
        "    Predice ya sea si la etiqueta es 0 o 1 usando los parámetros de regresión logística aprendidos (w, b) \n",
        "    \n",
        "    Argumentos:\n",
        "    w -- weights o pesos, un array numpy de tamaño (número atributos, 1)\n",
        "    b -- bias o sesgo, un escalar\n",
        "    X -- datos de tamño (número atributos, número de ejemplos)\n",
        "    \n",
        "    Returna:\n",
        "    Y_prediction -- un array numpy (vector) conteniendo todas las predicciones (0/1) para los ejemplos en X\n",
        "    '''\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    Y_prediction = np.zeros((1,m))\n",
        "    w = w.reshape(X.shape[0], 1)\n",
        "    \n",
        "    # Computa el vector A prediciendo las probabilidades de que esté divorciado en un evento\n",
        "    A = sigmoid(np.dot(w.T, X) + b)\n",
        "    \n",
        "    for i in range(A.shape[1]):\n",
        "        \n",
        "        # Convierte las probabilidades A[0, i] a las predicciones actuales p[0, i]\n",
        "        if A[0][i] <= 0.5:\n",
        "            Y_prediction[0][i] = 0\n",
        "        else:\n",
        "            Y_prediction[0][i] = 1\n",
        "    \n",
        "    assert(Y_prediction.shape == (1, m))\n",
        "    \n",
        "    return Y_prediction"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtAh03h1VJ1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FUNCIÓN: modelo\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
        "    \"\"\"\n",
        "    Construye el modelo de regresión logística llamando las funciones que implementamos anteriormente\n",
        "    \n",
        "    Argumentos:\n",
        "    X_train -- el conjunto de entrenamiento representado por un array numpy de tamaño (número atributos, m_train)\n",
        "    Y_train -- las etiquetas de entrenamiento representadas por un array numpy (vector) de tamaño (1, m_train)\n",
        "    X_test -- conjunto de prueba representadas por un array numpy de tamaño (número atributos, m_test)\n",
        "    Y_test -- etiquetas de la prueba representadas por un array numpy (vector)de tamaño (1, m_test)\n",
        "    num_iterations -- hiperparámetro representando los números de iteraciones para optimizar los parámetros\n",
        "    learning_rate -- hiperparámetro representando la tasa de aprendizaje usado en la regla de actualizacióón de optimize()\n",
        "    print_cost -- puesto en true imprime los costos cada 100 iteraciones\n",
        "    \n",
        "    Returna:\n",
        "    d -- dictionario conteniendo información sobre el modelo.\n",
        "    \"\"\"\n",
        "\n",
        "    # incializa los parámetros con ceros    \n",
        "    w, b = initialize_with_zeros(X_train.shape[0])\n",
        "\n",
        "    # Gradiente descendiente \n",
        "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
        "    \n",
        "    # Recupera los parámetros w y b desde el dictionario \"parametros\"\n",
        "    w = parameters[\"w\"]\n",
        "    b = parameters[\"b\"]\n",
        "    \n",
        "    # Predice los conjuntos prueba/entrenamiento \n",
        "    Y_prediction_test = predict(w, b, X_test)\n",
        "    Y_prediction_train = predict(w, b, X_train)\n",
        "\n",
        "    # imprime los errores de entrenamiento/prueba\n",
        "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
        "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
        "\n",
        "    \n",
        "    d = {\"costs\": costs,\n",
        "         \"Y_prediction_test\": Y_prediction_test, \n",
        "         \"Y_prediction_train\" : Y_prediction_train, \n",
        "         \"w\" : w, \n",
        "         \"b\" : b,\n",
        "         \"learning_rate\" : learning_rate,\n",
        "         \"num_iterations\": num_iterations}\n",
        "    \n",
        "    return d"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVtNy-GaW1KC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "00179e3e-b33c-4add-e729-69f69cc63de6"
      },
      "source": [
        "d = model(X_train, y_train, X_test, y_test, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.693147\n",
            "Cost after iteration 100: 0.487099\n",
            "Cost after iteration 200: 0.428639\n",
            "Cost after iteration 300: 0.384439\n",
            "Cost after iteration 400: 0.348096\n",
            "Cost after iteration 500: 0.317759\n",
            "Cost after iteration 600: 0.292211\n",
            "Cost after iteration 700: 0.270514\n",
            "Cost after iteration 800: 0.251937\n",
            "Cost after iteration 900: 0.235904\n",
            "Cost after iteration 1000: 0.221960\n",
            "Cost after iteration 1100: 0.209748\n",
            "Cost after iteration 1200: 0.198981\n",
            "Cost after iteration 1300: 0.189430\n",
            "Cost after iteration 1400: 0.180909\n",
            "Cost after iteration 1500: 0.173267\n",
            "Cost after iteration 1600: 0.166379\n",
            "Cost after iteration 1700: 0.160143\n",
            "Cost after iteration 1800: 0.154473\n",
            "Cost after iteration 1900: 0.149298\n",
            "train accuracy: 97.77777777777777 %\n",
            "test accuracy: 97.14285714285714 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rm1D1zsco1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "416a859a-d9db-440e-a380-e11ea43683fa"
      },
      "source": [
        "for enu, i in enumerate(d['Y_prediction_test'].T):\n",
        "    print(enu, i)\n",
        "print(type(d['Y_prediction_test']))\n",
        "    "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [1.]\n",
            "1 [1.]\n",
            "2 [1.]\n",
            "3 [1.]\n",
            "4 [1.]\n",
            "5 [0.]\n",
            "6 [1.]\n",
            "7 [1.]\n",
            "8 [1.]\n",
            "9 [1.]\n",
            "10 [1.]\n",
            "11 [1.]\n",
            "12 [1.]\n",
            "13 [1.]\n",
            "14 [1.]\n",
            "15 [1.]\n",
            "16 [1.]\n",
            "17 [0.]\n",
            "18 [0.]\n",
            "19 [0.]\n",
            "20 [0.]\n",
            "21 [0.]\n",
            "22 [0.]\n",
            "23 [0.]\n",
            "24 [0.]\n",
            "25 [0.]\n",
            "26 [0.]\n",
            "27 [0.]\n",
            "28 [0.]\n",
            "29 [0.]\n",
            "30 [0.]\n",
            "31 [0.]\n",
            "32 [0.]\n",
            "33 [0.]\n",
            "34 [0.]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDmCivyLc1hq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "9649126b-2796-4f83-eeee-57725a58ce44"
      },
      "source": [
        "for enu, i in enumerate(y_test.T):\n",
        "    print(enu, i)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [1]\n",
            "1 [1]\n",
            "2 [1]\n",
            "3 [1]\n",
            "4 [1]\n",
            "5 [1]\n",
            "6 [1]\n",
            "7 [1]\n",
            "8 [1]\n",
            "9 [1]\n",
            "10 [1]\n",
            "11 [1]\n",
            "12 [1]\n",
            "13 [1]\n",
            "14 [1]\n",
            "15 [1]\n",
            "16 [1]\n",
            "17 [0]\n",
            "18 [0]\n",
            "19 [0]\n",
            "20 [0]\n",
            "21 [0]\n",
            "22 [0]\n",
            "23 [0]\n",
            "24 [0]\n",
            "25 [0]\n",
            "26 [0]\n",
            "27 [0]\n",
            "28 [0]\n",
            "29 [0]\n",
            "30 [0]\n",
            "31 [0]\n",
            "32 [0]\n",
            "33 [0]\n",
            "34 [0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeyPpAF6c3pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}